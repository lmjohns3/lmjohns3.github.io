<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inconsolata&amp;family=Merriweather:ital,wght@0,400;0,600;1,400;1,600&amp;family=Work+Sans:wght@500&amp;display=swap"><link rel="stylesheet" href="https://unpkg.com/prismjs/themes/prism-tomorrow.css"><link rel="stylesheet" href="/lmjohns3.com.c37ba8ac.css"><title>lmjohns3</title></head><body><main><p>I enjoy making things‚Äîespecially software! üßë‚Äçüíª</p><p>For me, coding is a heady combination of üñãÔ∏è&nbsp;writing and
üß©&nbsp;puzzle solving and ‚ù§Ô∏è&nbsp;care. And sometimes the software ends
up being useful, too.&nbsp;üòÑ</p><p>Here are some of the projects I've worked on.
</p><article><h1><span>Theanets</span><a href="https://github.com/lmjohns3/theanets/"><img class="github" src="/github.9644546d.png"></a><a href="https://theanets.rtfd.org/">üìñ</a></h1><p><code>theanets</code> is a neural network toolkit for
<a href="https://python.org/">Python</a> that uses
<a href="https://deeplearning.net/software/theano">Theano</a> for the heavy
lifting. Thanks to Theano, your models will transparently run on a GPU.</p><p>The toolkit makes it easy to create a wide variety of machine learning
models, including linear dense and sparse autoencoders (e.g., PCA and ICA),
denoising autoencoders, linear and nonlinear regression, regularized
regression (e.g., lasso or elastic net), linear and nonlinear classifiers,
and recurrent autoencoders and classifiers, including models using LSTM
cells or Clockwork RNN layers.</p><p>Models can be constructed using different activation functions (e.g.,
linear, rectified linear, batch normalization, etc.) and different numbers
of layers (e.g., deep models). It is also easy to add different regularizers
to each of the models at optimization time&mdash;in fact, regularization is
often what differentiates two otherwise very similar models (e.g., PCA and
ICA).</p><div class="code"><pre><code class="language-python">import theanets, numpy as np

def sample(n): return np.random.randn(n, 10)

# create an autoencoder model.
ae = theanets.Autoencoder([10, 2, 10])

# train it with a sparsity regularizer.
ae.train(sample(1000), sample(100),
         algo='rmsprop', hidden_l1=0.1)

# continue training without the regularizer.
ae.train(sample(1000), sample(100),
         algo='nag', momentum=0.9)

# use the trained model.
ae.predict(sample(10))
</code></pre></div></article><article><h1><span>Downhill</span><a href="https://github.com/lmjohns3/downhill"><img class="github" src="/github.9644546d.png"></a><a href="https://downhill.rtfd.org/">üìñ</a></h1><img class="banana" src="https://downhill.readthedocs.org/en/latest/_images/rosenbrock-nag.png"><p><code>downhill</code> is a collection of stochastic gradient optimization
routines for loss functions defined using
<a href="https://deeplearning.net/software/theano">Theano</a>.</p><p>The package implements vanilla stochastic gradient descent (SGD), resilient
backpropagation, <a href="https://arxiv.org/abs/1502.04390">RMSProp</a>,
<a href="https://arxiv.org/abs/1212.5701">ADADELTA</a>,
<a href="https://arxiv.org/abs/1502.04390">Equilibrated SGD</a>, and
<a href="https://arxiv.org/abs/1412.6980">Adam</a>. All optimization
algorithms can be combined with traditional and
<a href="https://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_sutskever13.pdf">Nesterov (PDF)</a>
momentum.</p><div class="code"><pre><code class="language-python">import climate, downhill, theano, numpy as np
import theano.tensor as TT

climate.enable_default_logging()

def rand(*s): return np.random.randn(*s).astype('f')

# Set up a matrix factorization problem to optimize.
A, B, K = 20, 5, 3
u = theano.shared(rand(A, K), name='u')
v = theano.shared(rand(K, B), name='v')
e = TT.sqr(TT.matrix() - TT.dot(u, v))

# Create a noisy low-rank matrix to factor.
z = np.clip(rand(A, K) - 0.1, 0, 10)
y = np.dot(z, rand(K, B)) + rand(A, B)

downhill.minimize(
    # loss = |x - uv|_2 + |u|_1 + |v|_2
    loss=e.mean() + abs(u).mean() + (v * v).mean(),
    train=[y], batch_size=A, max_gradient_norm=1,
    learning_rate=0.1)

print('Sparse Coefficients:', u.get_value())
print('Basis:', v.get_value())
</code></pre></div></article><article><h1><span>Pagoda</span><a href="https://github.com/EmbodiedCognition/pagoda"><img class="github" src="/github.9644546d.png"></a></h1><p>Combines the ODE physics simulator with some OpenGL tools for
visualization, and a simple grammar for defining articulated bodies.</p><div class="code"><pre><code class="language-python">import click, pagoda, pagoda.viewer, numpy as np

# Implement a custom world reset that randomly repositions things.
class World(pagoda.physics.World):
    def reset(self):
        for b in self.bodies:
            b.position = np.array([0, 0, 10]) + 3 * rng.randn(3)
            b.quaternion = pagoda.physics.make_quaternion(
                np.pi * np.random.rand(), 0, 1, 1)

# Helper for generating gamma-distributed random values.
def gamma(n, k=0.1, size=1):
    return np.clip(np.random.gamma(n, k, size=size), 0.5, 1000)

w = World()

# Create 100 bodies in the world -- random shape, size, and color.
for _ in range(100):
    shape, kwargs = sorted(dict(
        box=dict(lengths=gamma(8, size=3)),
        capsule=dict(radius=gamma(3), length=gamma(10)),
        cylinder=dict(radius=gamma(2), length=gamma(10)),
        sphere=dict(radius=gamma(2)),
    ).items())[np.random.randint(4)]

    body = w.create_body(shape, **kwargs)
    body.color = tuple(np.random.uniform(0, 1, size=3)) + (0.9, )

# Run the simulation!
w.reset()
pagoda.viewer.Viewer(w).run()
</code></pre></div></article><article><h1>Others</h1><dl><dt><a href="https://github.com/EmbodiedCognition/py-c3d">py-c3d</a></dt><dd>A small set of utilities‚Äîat this point consisting of a file reader and writer, and a simple OpenGL visualization tool‚Äîfor dealing with motion capture data files in the <a href="https://www.c3d.org/html/default.htm">C3D binary format</a>.</dd><dt><a href="https://github.com/lmjohns3/py-depparse">py-depparse</a></dt><dd>A Python library and command-line tool for non-projective <a href="https://en.wikipedia.org/wiki/Parsing">dependency parsing</a> of natural language text.</dd><dt><a href="https://github.com/lmjohns3/kohonen">kohonen</a></dt><dd>A collection of several vector quantizers, including <a href="https://en.wikipedia.org/wiki/Self-organizing_map">self-organizing (Kohonen) map</a>, <a href="https://en.wikipedia.org/wiki/Neural_gas">neural gas</a>, and <a href="https://en.wikipedia.org/wiki/Growing_neural_gas">growing neural gas</a>.</dd><dt><a href="https://github.com/lmjohns3/py-rbm">py-rbm</a></dt><dd>Single-module implementation of Several types of Restricted Boltzmann Machines.</dd><dt><a href="https://github.com/lmjohns3/py-trm">py-trm</a></dt><dd>A Python wrapper for the <a href="https://gnu.org/software/gnuspeech">Gnuspeech</a> Tube Resonance Model, a vocal synthesizer.</dd></dl></article><footer><p>IÔ∏è ‚ù§Ô∏è <a href="https://en.wikipedia.org/wiki/Penrose_tiling">Penrose tilings</a>!</p><p class="license" xmlns:dct="http://purl.org/dc/terms/" xmlns:cc="http://creativecommons.org/ns#">The content on this web site is licensed under
<a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>
<img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1">
<img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1">
<img src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1">
</p></footer></main><svg id="penrose" preserveAspectRatio="xMidYMid slice"></svg><script src="/penrose.84634bf1.js"></script><script src="https://unpkg.com/prismjs/components/prism-core.min.js"></script><script src="https://unpkg.com/prismjs/plugins/autoloader/prism-autoloader.min.js"></script></body></html>